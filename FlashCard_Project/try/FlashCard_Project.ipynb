{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/data/danish_words.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     danish_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/data/words_to_learn.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DataScience/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DataScience/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DataScience/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DataScience/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DataScience/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/data/words_to_learn.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m     danish_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/data/words_to_learn.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     original_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/data/danish_words.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     to_learn \u001b[38;5;241m=\u001b[39m original_data\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m     original_data\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/data/words_to_learn.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DataScience/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DataScience/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DataScience/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DataScience/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DataScience/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/data/danish_words.csv'"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from tkinter import messagebox, ttk, END\n",
    "import os\n",
    "import re\n",
    "import smtplib\n",
    "import locale\n",
    "from dotenv import load_dotenv\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from tkinter import ttk\n",
    "from natsort import natsorted, ns\n",
    "import pyttsx3\n",
    "\n",
    "load_dotenv()\n",
    "BACKGROUND_COLOR = \"#B1DDC6\"\n",
    "current_card = {}\n",
    "to_learn = {}\n",
    "FONT_NAME = \"Courier\"\n",
    "\n",
    "try:\n",
    "    danish_data = pd.read_csv('./data/data/words_to_learn.csv')\n",
    "except FileNotFoundError:\n",
    "    original_data = pd.read_csv('./data/data/danish_words.csv')\n",
    "    to_learn = original_data.to_dict(orient='records')\n",
    "    original_data.to_csv('./data/data/words_to_learn.csv', index=False)\n",
    "else:\n",
    "    to_learn = danish_data.to_dict(orient='records')\n",
    "\n",
    "def next_card():\n",
    "    global current_card, flip_timer\n",
    "    window.after_cancel(flip_timer)\n",
    "    current_card = random.choice(to_learn)\n",
    "    canvas.itemconfig(card_title, text='Danish', fill='black')\n",
    "    canvas.itemconfig(card_word, text=current_card['Danish'], fill='black')\n",
    "    canvas.itemconfig(card_background, image=front_card)\n",
    "    flip_timer = window.after(3000, func=flip_card)\n",
    "\n",
    "def flip_card():\n",
    "    canvas.itemconfig(card_title, text='English', fill='white')\n",
    "    canvas.itemconfig(card_word, text=current_card['English'], fill='white')\n",
    "    canvas.itemconfig(card_background, image=back_card)\n",
    "\n",
    "def update_progress(value):\n",
    "    progress['value'] = value\n",
    "    window.update_idletasks()\n",
    "\n",
    "def increment_progress(current, total):\n",
    "    value = (current / total) * 100\n",
    "    update_progress(value)\n",
    "\n",
    "current_word_index = 0\n",
    "total_words = len(to_learn)\n",
    "\n",
    "def is_known():\n",
    "    global current_word_index, current_card\n",
    "    if current_card in to_learn:\n",
    "        to_learn.remove(current_card)\n",
    "        current_word_index += 1\n",
    "        increment_progress(current_word_index, total_words)\n",
    "        data = pd.DataFrame(to_learn)\n",
    "        data.to_csv('./data/data/words_to_learn.csv', index=False)\n",
    "        next_card()\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'da_DK.UTF-8')\n",
    "\n",
    "def show_data():\n",
    "    try:\n",
    "        data = pd.read_csv('./data/data/danish_words.csv')\n",
    "        prefixes_to_exclude = ('en ', 'et ', 'at ', 'af ', 'i ', 'på ', 'til ', 'med ', 'om ', 'ud ')\n",
    "\n",
    "        def remove_prefix(word):\n",
    "            for prefix in prefixes_to_exclude:\n",
    "                if word.startswith(prefix):\n",
    "                    return word[len(prefix):]\n",
    "            return word\n",
    "\n",
    "        data['sort_key'] = data['Danish'].apply(remove_prefix)\n",
    "        data = data.loc[natsorted(data.index, key=lambda x: data.loc[x, 'sort_key'], alg=ns.LOCALE)].reset_index(drop=True)\n",
    "        data = data.drop(columns='sort_key')\n",
    "\n",
    "        data_window = Toplevel(window)\n",
    "        data_window.title(\"Saved Data\")\n",
    "\n",
    "        # Search bar\n",
    "        search_frame = Frame(data_window)\n",
    "        search_frame.pack(pady=5)\n",
    "        Label(search_frame, text=\"Search:\", font=(FONT_NAME, 12)).pack(side=LEFT, padx=5)\n",
    "        search_entry = Entry(search_frame, width=30)\n",
    "        search_entry.pack(side=LEFT, padx=5)\n",
    "\n",
    "        # Create a Treeview widget\n",
    "        tree = ttk.Treeview(data_window, columns=(\"Danish\", \"English\"), show='headings', height=15)\n",
    "        tree.heading(\"Danish\", text=\"Danish\")\n",
    "        tree.heading(\"English\", text=\"English\")\n",
    "        tree.pack(padx=10, pady=10)\n",
    "\n",
    "        def populate_tree(data_subset):\n",
    "            for item in tree.get_children():\n",
    "                tree.delete(item)\n",
    "            for _, row in data_subset.iterrows():\n",
    "                tree.insert('', END, values=(row['Danish'], row['English']))\n",
    "\n",
    "        populate_tree(data)\n",
    "\n",
    "        # Search functionality\n",
    "        def search_word():\n",
    "            search_text = search_entry.get().strip().lower()\n",
    "            filtered_data = data[(data['Danish'].str.lower().str.contains(search_text)) | \n",
    "                                 (data['English'].str.lower().str.contains(search_text))]\n",
    "            populate_tree(filtered_data)\n",
    "\n",
    "        search_entry.bind(\"<KeyRelease>\", lambda event: search_word())\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        messagebox.showerror(title=\"Error\", message=\"No data file found!\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        messagebox.showerror(title=\"Error\", message=\"The data file is empty!\")\n",
    "    except locale.Error as e:\n",
    "        messagebox.showerror(title=\"Locale Error\", message=f\"Locale error: {e}\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(title=\"Error\", message=f\"An error occurred: {e}\")\n",
    "\n",
    "def send_to_mail():\n",
    "    global input_send_mail\n",
    "    mail_window = Toplevel(window)\n",
    "    mail_window.title('Send Mail')\n",
    "    Label(mail_window, text='Input your mail: ', font=(FONT_NAME, 12)).grid(\n",
    "        column=0, row=0, sticky='e', padx=10, pady=5)\n",
    "    input_send_mail = Entry(mail_window, width=30)\n",
    "    input_send_mail.grid(column=1, row=0)\n",
    "\n",
    "    Button(mail_window, text='Send',\n",
    "           command=lambda: send(input_send_mail)).grid(column=2, row=0)\n",
    "\n",
    "def send(input_send_mail):\n",
    "    send_mail = input_send_mail.get()\n",
    "    if not re.search(r\"^\\w+@\\w+\\.\\w+$\", send_mail):\n",
    "        messagebox.showwarning(title=\"Warning\", message=\"Invalid email address!\")\n",
    "        return\n",
    "\n",
    "    mail = os.getenv('MAIL')\n",
    "    password = os.getenv('PASSWORD')\n",
    "    recipients = send_mail\n",
    "    subject = 'Data Export'\n",
    "    smtp_server = 'smtp.gmail.com'\n",
    "    smtp_port = 587\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = mail\n",
    "    msg['To'] = recipients\n",
    "    msg['Subject'] = subject\n",
    "\n",
    "    body = \"Please find the attached data.json file.\"\n",
    "    body_part = MIMEText(body, 'plain')\n",
    "    msg.attach(body_part)\n",
    "\n",
    "    data_file_path = './data/data/words_to_learn.csv'\n",
    "\n",
    "    try:\n",
    "        with open(data_file_path, 'rb') as file:\n",
    "            file_part = MIMEApplication(file.read(), Name=\"data.txt\")\n",
    "            file_part['Content-Disposition'] = 'attachment; filename=\"data.txt\"'\n",
    "            msg.attach(file_part)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(title=\"Error\", message=f\"Could not attach file: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with smtplib.SMTP(smtp_server, smtp_port) as connection:\n",
    "            connection.starttls()\n",
    "            connection.login(user=mail, password=password)\n",
    "            connection.sendmail(from_addr=mail, to_addrs=recipients, msg=msg.as_string())\n",
    "        messagebox.showinfo(title=\"Success\", message=\"Email sent successfully!\")\n",
    "        if os.path.exists(data_file_path):\n",
    "            os.remove(data_file_path)\n",
    "            messagebox.showinfo(title=\"File Removed\", message=\"words_to_learn.csv has been deleted.\")\n",
    "        else:\n",
    "            messagebox.showwarning(title=\"File Not Found\", message=\"The file was not found for deletion.\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(title=\"Error\", message=f\"Error sending email: {e}\")\n",
    "    finally:\n",
    "        input_send_mail.delete(0, END)\n",
    "\n",
    "def add_edit_or_delete_word():\n",
    "    edit_window = Toplevel(window)\n",
    "    edit_window.title(\"Add/Edit/Delete Words\")\n",
    "\n",
    "    try:\n",
    "        data = pd.read_csv('./data/data/danish_words.csv')\n",
    "        prefixes_to_exclude = ('en ', 'et ', 'at ', 'af ', 'i ', 'på ', 'til ', 'med ', 'om ', 'ud ')\n",
    "\n",
    "        def remove_prefix(word):\n",
    "            for prefix in prefixes_to_exclude:\n",
    "                if word.startswith(prefix):\n",
    "                    return word[len(prefix):]\n",
    "            return word\n",
    "\n",
    "        data['sort_key'] = data['Danish'].apply(remove_prefix)\n",
    "        data = data.loc[natsorted(data.index, key=lambda x: data.loc[x, 'sort_key'], alg=ns.LOCALE)].reset_index(drop=True)\n",
    "        data = data.drop(columns='sort_key')\n",
    "        data_list = data.to_dict(orient='records')\n",
    "\n",
    "        # Search bar\n",
    "        search_frame = Frame(edit_window)\n",
    "        search_frame.pack(pady=5)\n",
    "        Label(search_frame, text=\"Search:\", font=(FONT_NAME, 12)).pack(side=LEFT, padx=5)\n",
    "        search_entry = Entry(search_frame, width=30)\n",
    "        search_entry.pack(side=LEFT, padx=5)\n",
    "\n",
    "        # Frame for Treeview and buttons\n",
    "        frame = Frame(edit_window)\n",
    "        frame.pack(pady=10)\n",
    "\n",
    "        # Create a Treeview widget\n",
    "        tree = ttk.Treeview(frame, columns=(\"Danish\", \"English\"), show='headings', height=15)\n",
    "        tree.heading(\"Danish\", text=\"Danish\")\n",
    "        tree.heading(\"English\", text=\"English\")\n",
    "        tree.pack()\n",
    "\n",
    "        def populate_tree(data_subset):\n",
    "            for item in tree.get_children():\n",
    "                tree.delete(item)\n",
    "            for row in data_subset:\n",
    "                tree.insert('', END, values=(row['Danish'], row['English']))\n",
    "\n",
    "        populate_tree(data_list)\n",
    "\n",
    "        # Search words\n",
    "        def search_word():\n",
    "            search_text = search_entry.get().strip().lower()\n",
    "            filtered_data = [row for row in data_list if search_text in row['Danish'].lower() or search_text in row['English'].lower()]\n",
    "            populate_tree(filtered_data)\n",
    "\n",
    "        search_entry.bind(\"<KeyRelease>\", lambda event: search_word())\n",
    "\n",
    "        def add_new_word():\n",
    "            add_window = Toplevel(edit_window)\n",
    "            add_window.title(\"Add New Word\")\n",
    "\n",
    "            Label(add_window, text=\"Danish:\", font=(FONT_NAME, 12)).grid(row=0, column=0, padx=10, pady=5)\n",
    "            danish_entry = Entry(add_window, width=30)\n",
    "            danish_entry.grid(row=0, column=1, padx=10, pady=5)\n",
    "\n",
    "            Label(add_window, text=\"English:\", font=(FONT_NAME, 12)).grid(row=1, column=0, padx=10, pady=5)\n",
    "            english_entry = Entry(add_window, width=30)\n",
    "            english_entry.grid(row=1, column=1, padx=10, pady=5)\n",
    "\n",
    "            def save_new_word():\n",
    "                danish = danish_entry.get().strip()\n",
    "                english = english_entry.get().strip()\n",
    "\n",
    "                if not danish or not english:\n",
    "                    messagebox.showwarning(\"Warning\", \"Both fields must be filled.\")\n",
    "                    return\n",
    "\n",
    "                if (danish, english) in [(row['Danish'], row['English']) for row in data_list]:\n",
    "                    messagebox.showinfo(\"Duplicate\", \"This word pair already exists!\")\n",
    "                    return\n",
    "\n",
    "                with open('./data/data/danish_words.csv', 'a') as fd:\n",
    "                    fd.write(f\"\\n{danish},{english}\")\n",
    "                messagebox.showinfo(\"Success\", \"Word added successfully!\")\n",
    "                data_list.append({'Danish': danish, 'English': english})\n",
    "                populate_tree(data_list)\n",
    "                add_window.destroy()\n",
    "\n",
    "            Button(add_window, text=\"Save\", command=save_new_word).grid(row=2, column=0, columnspan=2, pady=10)\n",
    "\n",
    "        def edit_selected():\n",
    "            selected_item = tree.selection()\n",
    "            if not selected_item:\n",
    "                messagebox.showwarning(\"Warning\", \"Please select a word to edit.\")\n",
    "                return\n",
    "\n",
    "            edit_item = tree.item(selected_item)['values']\n",
    "            edit_window_inner = Toplevel(edit_window)\n",
    "            edit_window_inner.title(\"Edit Word\")\n",
    "\n",
    "            Label(edit_window_inner, text=\"Danish:\", font=(FONT_NAME, 12)).grid(row=0, column=0, padx=10, pady=5)\n",
    "            danish_entry = Entry(edit_window_inner, width=30)\n",
    "            danish_entry.grid(row=0, column=1, padx=10, pady=5)\n",
    "            danish_entry.insert(0, edit_item[0])\n",
    "\n",
    "            Label(edit_window_inner, text=\"English:\", font=(FONT_NAME, 12)).grid(row=1, column=0, padx=10, pady=5)\n",
    "            english_entry = Entry(edit_window_inner, width=30)\n",
    "            english_entry.grid(row=1, column=1, padx=10, pady=5)\n",
    "            english_entry.insert(0, edit_item[1])\n",
    "\n",
    "            def save_changes():\n",
    "                new_danish = danish_entry.get().strip()\n",
    "                new_english = english_entry.get().strip()\n",
    "\n",
    "                if not new_danish or not new_english:\n",
    "                    messagebox.showwarning(\"Warning\", \"Both fields must be filled.\")\n",
    "                    return\n",
    "\n",
    "                data.loc[(data['Danish'] == edit_item[0]) & (data['English'] == edit_item[1]), ['Danish', 'English']] = [new_danish, new_english]\n",
    "                data.to_csv('./data/data/danish_words.csv', index=False)\n",
    "                messagebox.showinfo(\"Success\", \"Word updated successfully!\")\n",
    "                data_list = data.to_dict(orient='records')\n",
    "                populate_tree(data_list)\n",
    "                edit_window_inner.destroy()\n",
    "\n",
    "            Button(edit_window_inner, text=\"Save\", command=save_changes).grid(row=2, column=0, columnspan=2, pady=10)\n",
    "\n",
    "        def delete_selected():\n",
    "            selected_item = tree.selection()\n",
    "            if not selected_item:\n",
    "                messagebox.showwarning(\"Warning\", \"Please select a word to delete.\")\n",
    "                return\n",
    "\n",
    "            delete_item = tree.item(selected_item)['values']\n",
    "            result = messagebox.askyesno(\"Confirmation\", f\"Are you sure you want to delete '{delete_item[0]}'?\")\n",
    "            if result:\n",
    "                data.drop(data[(data['Danish'] == delete_item[0]) & (data['English'] == delete_item[1])].index, inplace=True)\n",
    "                data.to_csv('./data/data/danish_words.csv', index=False)\n",
    "                messagebox.showinfo(\"Success\", \"Word deleted successfully!\")\n",
    "                data_list = data.to_dict(orient='records')\n",
    "                populate_tree(data_list)\n",
    "\n",
    "        Button(frame, text=\"Add New Word\", command=add_new_word).pack(side=LEFT, padx=10, pady=5)\n",
    "        Button(frame, text=\"Edit Selected\", command=edit_selected).pack(side=LEFT, padx=10, pady=5)\n",
    "        Button(frame, text=\"Delete Selected\", command=delete_selected).pack(side=RIGHT, padx=10, pady=5)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        messagebox.showerror(\"Error\", \"No data file found!\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        messagebox.showerror(\"Error\", \"The data file is empty!\")\n",
    "\n",
    "def speak():\n",
    "    try:\n",
    "        engine = pyttsx3.init()\n",
    "        voices = engine.getProperty('voices')\n",
    "        danish_voice_id = None\n",
    "\n",
    "        for voice in voices:\n",
    "            if 'da' in voice.languages or 'Danish' in voice.name:\n",
    "                danish_voice_id = voice.id\n",
    "                break\n",
    "\n",
    "        engine.setProperty('voice', danish_voice_id)\n",
    "        engine.setProperty('rate', 125)\n",
    "        engine.say(current_card['Danish'])\n",
    "        engine.runAndWait()\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred while trying to speak: {e}\")\n",
    "\n",
    "# User Interface\n",
    "window = Tk()\n",
    "window.config(padx=50, pady=50, bg=BACKGROUND_COLOR)\n",
    "window.title('Flash Cards')\n",
    "\n",
    "flip_timer = window.after(5000, func=flip_card)\n",
    "\n",
    "canvas = Canvas(width=800, height=526, highlightthickness=0)\n",
    "front_card = PhotoImage(file='./data/images/card_front.png')\n",
    "back_card = PhotoImage(file='./data/images/card_back.png')\n",
    "card_background = canvas.create_image(400, 263, image=front_card)\n",
    "card_title = canvas.create_text(400, 150, text='Title', font=('Ariel', 40, 'italic'))\n",
    "card_word = canvas.create_text(400, 263, text='WORD', font=('Ariel', 60, 'bold'))\n",
    "canvas.config(bg=BACKGROUND_COLOR)\n",
    "canvas.grid(column=0, row=0, columnspan=3)\n",
    "\n",
    "progress = ttk.Progressbar(window, orient=HORIZONTAL, length=300, mode='determinate')\n",
    "progress.grid(column=0, row=4, columnspan=3, pady=20)\n",
    "\n",
    "# Button images\n",
    "ok_button = PhotoImage(file='./data/images/right.png')\n",
    "false_button = PhotoImage(file='./data/images/wrong.png')\n",
    "correct_button = Button(image=ok_button, highlightbackground=BACKGROUND_COLOR,\n",
    "                        highlightcolor=BACKGROUND_COLOR, highlightthickness=4, relief='solid', command=is_known)\n",
    "correct_button.grid(column=2, row=1)\n",
    "wrong_button = Button(image=false_button, highlightbackground=BACKGROUND_COLOR,\n",
    "                      highlightcolor=BACKGROUND_COLOR, highlightthickness=4, relief='solid', command=next_card)\n",
    "wrong_button.grid(column=0, row=1)\n",
    "send_button = Button(text='Send to mail', highlightbackground=BACKGROUND_COLOR,\n",
    "                     highlightcolor=BACKGROUND_COLOR, highlightthickness=4, relief='solid', command=send_to_mail)\n",
    "send_button.grid(column=0, row=2)\n",
    "\n",
    "button_show = Button(text='Show data', highlightbackground=BACKGROUND_COLOR,\n",
    "                     highlightcolor=BACKGROUND_COLOR, highlightthickness=4, relief='solid', command=show_data)\n",
    "button_show.grid(column=1, row=2)\n",
    "\n",
    "edit_button_main = Button(text='Add/Edit/Delete Words', highlightbackground=BACKGROUND_COLOR,\n",
    "                          highlightcolor=BACKGROUND_COLOR, highlightthickness=4, relief='solid', command=add_edit_or_delete_word)\n",
    "edit_button_main.grid(column=1, row=3)\n",
    "\n",
    "speak_button = Button(text='Speaker', highlightbackground=BACKGROUND_COLOR,\n",
    "                      highlightcolor=BACKGROUND_COLOR, highlightthickness=4, relief='solid', command=speak)\n",
    "speak_button.grid(column=1, row=1)\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
